# Web-Scraping-GitHub-Data
PROJECT OUTLINE:
For top featured topics, in the topics column of GitHub page, gather the title, topic Description & topic url .
Save this in the pandas Data Frame form.
For each topic, Scrape the Username, Repository Name, repository url and No. of Stars for:
Top 30 repositories in each topic
At the end, save the data in CSV form at a specific folder path.

Tools Used: Python, Requests module, BeautifulSoup, Pandas, os module, Jupyter Notebook


What motivated me to do this project? I love playing with data, and I was interested in the process of collection of large amount of data and what are the requirements to do so. So, I gathered all the informations and build this project to Scrape the data and use it for the analysis. I learnt many things while creating it!!
